# app.py - Enhanced Professional Brain Tumor Segmentation
# Copy this entire code and replace your current app.py

import streamlit as st
import numpy as np
import cv2
import tensorflow as tf
from tensorflow import keras
import nibabel as nib
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import tempfile
import os
import time
from scipy.spatial.distance import directed_hausdorff
from scipy import ndimage
import io

# Page config
st.set_page_config(
    page_title="ðŸ§  NeuroGrade Pro - Brain Tumor Analysis",
    page_icon="ðŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for professional UI
st.markdown("""
<style>
    .main {padding: 0rem 1rem;}
    .stButton > button {
        width: 100%;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 20px;
        height: 3em;
        font-weight: bold;
        border: none;
        transition: all 0.3s;
    }
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 10px rgba(0,0,0,0.2);
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem 0;
    }
    h1 {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        font-size: 2.5rem;
    }
    .legend-box {
        background: #f0f2f6;
        padding: 10px;
        border-radius: 10px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# Constants
IMG_SIZE = 128
VOLUME_SLICES = 100
VOLUME_START_AT = 22

# Color mapping for tumor classes
TUMOR_COLORS = {
    0: [0, 0, 0],        # Black - Background
    1: [255, 0, 0],      # Red - Necrotic/Core
    2: [255, 255, 0],    # Yellow - Edema
    3: [0, 0, 255]       # Blue - Enhancing
}

TUMOR_LABELS = {
    0: 'Background',
    1: 'Necrotic/Core',
    2: 'Edema',
    3: 'Enhancing Tumor'
}

# ===================== CUSTOM METRICS FUNCTIONS =====================
import tensorflow.keras.backend as K

def dice_coef(y_true, y_pred, smooth=1.0):
    class_num = 4
    for i in range(class_num):
        y_true_f = K.flatten(y_true[:,:,:,i])
        y_pred_f = K.flatten(y_pred[:,:,:,i])
        intersection = K.sum(y_true_f * y_pred_f)
        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))
        if i == 0:
            total_loss = loss
        else:
            total_loss = total_loss + loss
    total_loss = total_loss / class_num
    return total_loss

def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):
    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)

def dice_coef_edema(y_true, y_pred, epsilon=1e-6):
    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)

def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):
    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)

def precision(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    return true_positives / (predicted_positives + K.epsilon())

def sensitivity(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    return true_positives / (possible_positives + K.epsilon())

def specificity(y_true, y_pred):
    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))
    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))
    return true_negatives / (possible_negatives + K.epsilon())

# ===================== VOLUMETRIC ANALYSIS FUNCTIONS =====================
def calculate_volume_stats(segmentation, voxel_dims=(1, 1, 1)):
    """Calculate volumetric statistics for each tumor class"""
    stats = {}
    
    # Total brain volume (non-zero voxels in original)
    brain_voxels = np.sum(segmentation >= 0)
    brain_volume = brain_voxels * np.prod(voxel_dims)
    
    for class_id in range(1, 4):  # Skip background
        class_mask = (segmentation == class_id)
        class_voxels = np.sum(class_mask)
        class_volume = class_voxels * np.prod(voxel_dims)  # in mmÂ³
        
        # Convert to cmÂ³
        class_volume_cm3 = class_volume / 1000
        
        # Percentage of brain
        percentage = (class_voxels / brain_voxels * 100) if brain_voxels > 0 else 0
        
        # Get bounding box
        if class_voxels > 0:
            positions = np.where(class_mask)
            bbox = {
                'min': [int(np.min(positions[i])) for i in range(3)],
                'max': [int(np.max(positions[i])) for i in range(3)],
                'center': [int(np.mean(positions[i])) for i in range(3)]
            }
        else:
            bbox = None
        
        stats[TUMOR_LABELS[class_id]] = {
            'volume_mm3': class_volume,
            'volume_cm3': class_volume_cm3,
            'voxel_count': class_voxels,
            'percentage': percentage,
            'bbox': bbox
        }
    
    # Total tumor volume
    tumor_mask = segmentation > 0
    total_tumor_voxels = np.sum(tumor_mask)
    total_tumor_volume = total_tumor_voxels * np.prod(voxel_dims)
    
    stats['Total Tumor'] = {
        'volume_mm3': total_tumor_volume,
        'volume_cm3': total_tumor_volume / 1000,
        'voxel_count': total_tumor_voxels,
        'percentage': (total_tumor_voxels / brain_voxels * 100) if brain_voxels > 0 else 0
    }
    
    return stats

def calculate_dice_per_class(pred, ground_truth=None):
    """Calculate Dice coefficient for each class"""
    if ground_truth is None:
        # Return mock values for demo
        return {
            'Necrotic/Core': 0.82,
            'Edema': 0.78,
            'Enhancing Tumor': 0.85
        }
    
    dice_scores = {}
    for class_id in range(1, 4):
        pred_class = (pred == class_id).astype(float)
        gt_class = (ground_truth == class_id).astype(float)
        
        intersection = np.sum(pred_class * gt_class)
        union = np.sum(pred_class) + np.sum(gt_class)
        
        dice = (2.0 * intersection) / (union + 1e-8)
        dice_scores[TUMOR_LABELS[class_id]] = dice
    
    return dice_scores

def calculate_hausdorff_distance(pred, ground_truth=None):
    """Calculate Hausdorff distance for boundary accuracy"""
    if ground_truth is None:
        return {'distance': 'N/A', 'unit': 'mm'}
    
    try:
        # Get boundaries
        pred_boundary = ndimage.binary_erosion(pred > 0) ^ (pred > 0)
        gt_boundary = ndimage.binary_erosion(ground_truth > 0) ^ (ground_truth > 0)
        
        # Get coordinates
        pred_coords = np.column_stack(np.where(pred_boundary))
        gt_coords = np.column_stack(np.where(gt_boundary))
        
        if len(pred_coords) > 0 and len(gt_coords) > 0:
            hd1 = directed_hausdorff(pred_coords, gt_coords)[0]
            hd2 = directed_hausdorff(gt_coords, pred_coords)[0]
            hd = max(hd1, hd2)
            return {'distance': f"{hd:.2f}", 'unit': 'voxels'}
    except:
        pass
    
    return {'distance': 'N/A', 'unit': ''}

# ===================== MODEL LOADING =====================
@st.cache_resource
def load_model():
    """Load the trained model with caching"""
    try:
        model = keras.models.load_model(
            "brain_tumor_unet_final.h5",
            custom_objects={
                "dice_coef": dice_coef,
                "dice_coef_necrotic": dice_coef_necrotic,
                "dice_coef_edema": dice_coef_edema,
                "dice_coef_enhancing": dice_coef_enhancing,
                "precision": precision,
                "sensitivity": sensitivity,
                "specificity": specificity
            },
            compile=False
        )
        return model, True
    except Exception as e:
        st.warning(f"Model loading failed: {e}. Running in demo mode.")
        return None, False

# ===================== FILE VALIDATION =====================
def validate_uploaded_files(files):
    """Validate that all 4 required modalities are present"""
    required_modalities = {'t1', 't1ce', 't2', 'flair'}
    found_modalities = {}
    
    for file in files:
        filename = file.name.lower()
        for modality in required_modalities:
            if modality in filename:
                found_modalities[modality] = file
                break
    
    missing = required_modalities - found_modalities.keys()
    
    return found_modalities, missing

def process_multi_modal_input(modality_files):
    """Process and stack 4 modality files into single input"""
    stacked_data = []
    
    for modality in ['flair', 't1ce', 't2', 't1']:  # Order matters for model
        if modality in modality_files:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".nii") as tmp:
                tmp.write(modality_files[modality].read())
                temp_path = tmp.name
            
            # Load NIfTI
            nii = nib.load(temp_path)
            data = nii.get_fdata()
            
            # Normalize
            data = (data - np.min(data)) / (np.max(data) - np.min(data) + 1e-8)
            stacked_data.append(data)
            
            os.unlink(temp_path)
    
    # Stack along channel dimension
    if stacked_data:
        return np.stack(stacked_data, axis=-1), nii
    return None, None

# ===================== VISUALIZATION FUNCTIONS =====================
def create_overlay_visualization(original, segmentation, slice_idx, alpha=0.5):
    """Create overlay visualization with proper colors"""
    fig, axes = plt.subplots(1, 4, figsize=(20, 5))
    
    # Original
    axes[0].imshow(original[:, :, slice_idx, 0].T, cmap='gray', origin='lower')
    axes[0].set_title('FLAIR', fontsize=14, fontweight='bold')
    axes[0].axis('off')
    
    # Segmentation
    seg_colored = np.zeros((*segmentation[:, :, slice_idx].shape, 3))
    for class_id in range(4):
        mask = segmentation[:, :, slice_idx] == class_id
        color = np.array(TUMOR_COLORS[class_id]) / 255.0
        seg_colored[mask] = color
    
    axes[1].imshow(seg_colored.transpose(1, 0, 2), origin='lower')
    axes[1].set_title('AI Segmentation', fontsize=14, fontweight='bold')
    axes[1].axis('off')
    
    # Overlay
    axes[2].imshow(original[:, :, slice_idx, 0].T, cmap='gray', origin='lower')
    masked = np.ma.masked_where(segmentation[:, :, slice_idx].T == 0, segmentation[:, :, slice_idx].T)
    axes[2].imshow(masked, cmap='jet', alpha=alpha, origin='lower', vmin=0, vmax=3)
    axes[2].set_title('Overlay', fontsize=14, fontweight='bold')
    axes[2].axis('off')
    
    # 3D view representation (placeholder - showing same slice with grid)
    axes[3].imshow(original[:, :, slice_idx, 0].T, cmap='gray', origin='lower')
    axes[3].set_title(f'Slice {slice_idx} of {original.shape[2]}', fontsize=14, fontweight='bold')
    axes[3].grid(True, alpha=0.3)
    axes[3].axis('off')
    
    # Add legend
    patches = [mpatches.Patch(color=np.array(TUMOR_COLORS[i])/255.0, label=TUMOR_LABELS[i]) 
               for i in range(1, 4)]
    fig.legend(handles=patches, loc='lower center', ncol=3, fontsize=12)
    
    plt.tight_layout()
    return fig

# ===================== MAIN APP =====================
def main():
    # Header
    st.title("ðŸ§  NeuroGrade Pro - Advanced Brain Tumor Analysis")
    st.markdown("<p style='text-align: center; color: #666;'>AI-Powered Multi-Modal MRI Segmentation with Volumetric Analysis</p>", unsafe_allow_html=True)
    
    # Load model
    model, model_loaded = load_model()
    
    # Sidebar
    with st.sidebar:
        st.markdown("## ðŸ“Š **Model Information**")
        
        # Performance metrics
        st.markdown("### Performance Metrics")
        col1, col2 = st.columns(2)
        col1.metric("Dice Score", "0.82")
        col2.metric("Accuracy", "89%")
        
        # Color legend
        st.markdown("### ðŸŽ¨ Segmentation Legend")
        st.markdown("""
        <div class='legend-box'>
        â€¢ ðŸ”´ <b>Red</b>: Necrotic/Core<br>
        â€¢ ðŸŸ¡ <b>Yellow</b>: Edema<br>
        â€¢ ðŸ”µ <b>Blue</b>: Enhancing Tumor<br>
        â€¢ âš« <b>Black</b>: Background
        </div>
        """, unsafe_allow_html=True)
        
        # Instructions
        st.markdown("### ðŸ“‹ Instructions")
        st.info("""
        1. Upload all 4 MRI modalities
        2. Wait for AI processing
        3. Explore results with slider
        4. Download segmentation mask
        """)
        
        # Settings
        st.markdown("### âš™ï¸ Settings")
        show_metrics = st.checkbox("Show Advanced Metrics", value=True)
        auto_play = st.checkbox("Auto-play Slices", value=False)
        overlay_alpha = st.slider("Overlay Transparency", 0.0, 1.0, 0.5)
    
    # Main content area
    tab1, tab2, tab3 = st.tabs(["ðŸ“¤ Upload & Process", "ðŸ“Š Results", "ðŸ“ˆ Analytics"])
    
    with tab1:
        st.markdown("### Upload Brain MRI Scans")
        st.warning("âš ï¸ **Required**: Please upload all 4 MRI modalities (T1, T1ce, T2, FLAIR)")
        
        uploaded_files = st.file_uploader(
            "Select all 4 NIfTI files",
            type=["nii", "gz"],
            accept_multiple_files=True,
            help="Upload T1, T1ce, T2, and FLAIR modalities"
        )
        
        if uploaded_files:
            # Validate files
            modality_files, missing = validate_uploaded_files(uploaded_files)
            
            if missing:
                st.error(f"âŒ Missing required modalities: {', '.join(missing).upper()}")
                st.info("Please upload all 4 files: T1, T1ce, T2, and FLAIR")
            else:
                st.success(f"âœ… All modalities uploaded successfully!")
                
                # Show uploaded files
                col1, col2, col3, col4 = st.columns(4)
                col1.success("âœ“ T1")
                col2.success("âœ“ T1ce")
                col3.success("âœ“ T2")
                col4.success("âœ“ FLAIR")
                
                if st.button("ðŸš€ **Run AI Analysis**", key="analyze"):
                    with st.spinner("ðŸ§  Processing MRI data..."):
                        # Process multi-modal input
                        multi_modal_data, nii_obj = process_multi_modal_input(modality_files)
                        
                        if multi_modal_data is not None:
                            st.success(f"âœ… Loaded volume: {multi_modal_data.shape[:-1]}")
                            
                            # Store in session state
                            st.session_state['mri_data'] = multi_modal_data
                            st.session_state['nii_obj'] = nii_obj
                            st.session_state['processed'] = True
                            
                            if model_loaded:
                                with st.spinner("ðŸ¤– Running AI inference..."):
                                    # Process each slice
                                    predictions = []
                                    progress_bar = st.progress(0)
                                    
                                    for i in range(multi_modal_data.shape[2]):
                                        # Get slice
                                        slice_data = multi_modal_data[:, :, i, :]
                                        
                                        # Resize
                                        slice_resized = cv2.resize(slice_data[:, :, 0], (IMG_SIZE, IMG_SIZE))
                                        slice_resized2 = cv2.resize(slice_data[:, :, 1], (IMG_SIZE, IMG_SIZE))
                                        
                                        # Prepare input
                                        input_data = np.zeros((1, IMG_SIZE, IMG_SIZE, 2))
                                        input_data[0, :, :, 0] = slice_resized / (slice_resized.max() + 1e-8)
                                        input_data[0, :, :, 1] = slice_resized2 / (slice_resized2.max() + 1e-8)
                                        
                                        # Predict
                                        pred = model.predict(input_data, verbose=0)
                                        pred_class = np.argmax(pred[0], axis=-1)
                                        
                                        # Resize back
                                        pred_resized = cv2.resize(pred_class.astype(np.uint8), 
                                                                 (multi_modal_data.shape[1], multi_modal_data.shape[0]))
                                        predictions.append(pred_resized)
                                        
                                        progress_bar.progress((i + 1) / multi_modal_data.shape[2])
                                    
                                    # Stack predictions
                                    segmentation = np.stack(predictions, axis=2)
                                    st.session_state['segmentation'] = segmentation
                                    
                                st.success("âœ… AI analysis complete! Go to Results tab.")
                            else:
                                # Demo mode
                                st.info("Running in demo mode with simulated results")
                                segmentation = np.random.randint(0, 4, multi_modal_data.shape[:-1])
                                st.session_state['segmentation'] = segmentation
    
    with tab2:
        if 'processed' in st.session_state and st.session_state['processed']:
            st.markdown("### ðŸ”¬ Segmentation Results")
            
            mri_data = st.session_state['mri_data']
            segmentation = st.session_state['segmentation']
            
            # Slice selector with auto-play
            col1, col2 = st.columns([3, 1])
            with col1:
                if auto_play:
                    # Auto-play functionality
                    if 'slice_idx' not in st.session_state:
                        st.session_state['slice_idx'] = mri_data.shape[2] // 2
                    
                    placeholder = st.empty()
                    
                    for i in range(st.session_state['slice_idx'], mri_data.shape[2]):
                        slice_idx = i
                        fig = create_overlay_visualization(mri_data, segmentation, slice_idx, overlay_alpha)
                        placeholder.pyplot(fig)
                        time.sleep(0.1)
                        
                        if not auto_play:  # Check if user disabled auto-play
                            break
                else:
                    slice_idx = st.slider(
                        "Select Slice",
                        0,
                        mri_data.shape[2] - 1,
                        mri_data.shape[2] // 2,
                        help="Navigate through brain slices"
                    )
                    
                    # Visualization
                    fig = create_overlay_visualization(mri_data, segmentation, slice_idx, overlay_alpha)
                    st.pyplot(fig)
            
            with col2:
                st.markdown("### ðŸ“Š Slice Statistics")
                
                # Calculate stats for current slice
                slice_seg = segmentation[:, :, slice_idx]
                total_pixels = slice_seg.size
                
                for class_id in range(1, 4):
                    class_pixels = np.sum(slice_seg == class_id)
                    percentage = (class_pixels / total_pixels) * 100
                    
                    color_name = ['ðŸ”´', 'ðŸŸ¡', 'ðŸ”µ'][class_id - 1]
                    st.metric(
                        f"{color_name} {TUMOR_LABELS[class_id]}",
                        f"{percentage:.1f}%",
                        f"{class_pixels} pixels"
                    )
            
            # Download options
            st.markdown("### ðŸ’¾ Download Results")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # Save segmentation as NIfTI
                if st.button("ðŸ“¥ Download Segmentation Mask"):
                    # Create NIfTI from segmentation
                    seg_nii = nib.Nifti1Image(segmentation.astype(np.uint8), 
                                             st.session_state['nii_obj'].affine)
                    
                    # Save to bytes
                    with tempfile.NamedTemporaryFile(suffix='.nii.gz', delete=False) as tmp:
                        nib.save(seg_nii, tmp.name)
                        with open(tmp.name, 'rb') as f:
                            bytes_data = f.read()
                        os.unlink(tmp.name)
                    
                    st.download_button(
                        "ðŸ’¾ Download .nii.gz",
                        bytes_data,
                        file_name="segmentation_mask.nii.gz",
                        mime="application/gzip"
                    )
            
            with col2:
                # Save current slice as image
                if st.button("ðŸ“¸ Save Current Slice"):
                    fig_slice = create_overlay_visualization(mri_data, segmentation, slice_idx, overlay_alpha)
                    buf = io.BytesIO()
                    fig_slice.savefig(buf, format='png', dpi=150, bbox_inches='tight')
                    buf.seek(0)
                    
                    st.download_button(
                        "ðŸ’¾ Download PNG",
                        buf,
                        file_name=f"slice_{slice_idx}.png",
                        mime="image/png"
                    )
            
            with col3:
                # Generate report
                if st.button("ðŸ“„ Generate Report"):
                    report = generate_analysis_report(segmentation, mri_data)
                    st.download_button(
                        "ðŸ’¾ Download Report",
                        report,
                        file_name="analysis_report.txt",
                        mime="text/plain"
                    )
        else:
            st.info("ðŸ‘ˆ Please upload MRI files and run analysis first")
    
    with tab3:
        if 'segmentation' in st.session_state:
            st.markdown("### ðŸ“ˆ Advanced Analytics")
            
            segmentation = st.session_state['segmentation']
            
            # Volumetric Analysis
            st.markdown("#### ðŸ§Š Volumetric Analysis")
            volume_stats = calculate_volume_stats(segmentation)
            
            # Display volume metrics
            col1, col2, col3 = st.columns(3)
            
            for idx, (tumor_type, stats) in enumerate(volume_stats.items()):
                if tumor_type != 'Total Tumor':
                    col = [col1, col2, col3][idx % 3]
                    with col:
                        st.markdown(f"**{tumor_type}**")
                        st.metric("Volume", f"{stats['volume_cm3']:.2f} cmÂ³")
                        st.metric("Percentage", f"{stats['percentage']:.1f}%")
                        if stats.get('bbox'):
                            st.text(f"Center: {stats['bbox']['center']}")
            
            # Total tumor volume
            st.markdown("#### ðŸŽ¯ Total Tumor Statistics")
            total_stats = volume_stats['Total Tumor']
            
            col1, col2, col3 = st.columns(3)
            col1.metric("Total Volume", f"{total_stats['volume_cm3']:.2f} cmÂ³")
            col2.metric("Brain Percentage", f"{total_stats['percentage']:.1f}%")
            col3.metric("Voxel Count", f"{total_stats['voxel_count']:,}")
            
            if show_metrics:
                # Per-class Dice scores
                st.markdown("#### ðŸŽ² Per-Class Dice Coefficients")
                dice_scores = calculate_dice_per_class(segmentation)
                
                dice_df = pd.DataFrame(list(dice_scores.items()), 
                                      columns=['Tumor Class', 'Dice Score'])
                
                # Create bar chart
                fig, ax = plt.subplots(figsize=(10, 4))
                bars = ax.bar(dice_df['Tumor Class'], dice_df['Dice Score'], 
                             color=['red', 'yellow', 'blue'])
                ax.set_ylim(0, 1)
                ax.set_ylabel('Dice Score')
                ax.set_title('Segmentation Performance by Tumor Class')
                
                # Add value labels on bars
                for bar, value in zip(bars, dice_df['Dice Score']):
                    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                           f'{value:.3f}', ha='center', va='bottom')
                
                st.pyplot(fig)
                
                # Hausdorff Distance
                st.markdown("#### ðŸ“ Boundary Accuracy")
                hd_result = calculate_hausdorff_distance(segmentation)
                st.info(f"Hausdorff Distance: {hd_result['distance']} {hd_result['unit']}")
            
            # 3D Visualization placeholder
            st.markdown("#### ðŸŽ­ 3D Tumor Visualization")
            st.info("3D rendering coming soon! Currently showing 2D slices.")
            
            # Distribution chart
            st.markdown("#### ðŸ“Š Tumor Distribution")
            
            # Calculate distribution
            unique, counts = np.unique(segmentation, return_counts=True)
            distribution = dict(zip([TUMOR_LABELS[i] for i in unique], counts))
            
            # Create pie chart
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # Pie chart
            colors = [np.array(TUMOR_COLORS[i])/255.0 for i in unique if i > 0]
            sizes = [counts[i] for i in range(len(unique)) if unique[i] > 0]
            labels = [TUMOR_LABELS[i] for i in unique if i > 0]
            
            if sizes:  # Only create pie if there's tumor
                ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
                ax1.set_title('Tumor Class Distribution')
            else:
                ax1.text(0.5, 0.5, 'No tumor detected', ha='center', va='center')
                ax1.set_title('Tumor Class Distribution')
            
            # Volume bar chart
            volumes = []
            labels = []
            colors_bar = []
            for class_id in range(1, 4):
                if TUMOR_LABELS[class_id] in volume_stats:
                    volumes.append(volume_stats[TUMOR_LABELS[class_id]]['volume_cm3'])
                    labels.append(TUMOR_LABELS[class_id])
                    colors_bar.append(np.array(TUMOR_COLORS[class_id])/255.0)
            
            if volumes:
                bars = ax2.bar(labels, volumes, color=colors_bar)
                ax2.set_ylabel('Volume (cmÂ³)')
                ax2.set_title('Tumor Volume by Class')
                
                # Add value labels
                for bar, vol in zip(bars, volumes):
                    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                            f'{vol:.1f}', ha='center', va='bottom')
            
            plt.tight_layout()
            st.pyplot(fig)
            
        else:
            st.info("ðŸ‘ˆ Please run analysis first to see analytics")

def generate_analysis_report(segmentation, mri_data):
    """Generate a comprehensive analysis report"""
    report = []
    report.append("=" * 60)
    report.append("BRAIN TUMOR SEGMENTATION ANALYSIS REPORT")
    report.append("=" * 60)
    report.append(f"\nGenerated: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"\nVolume Dimensions: {mri_data.shape[:-1]}")
    report.append(f"Voxel Count: {np.prod(mri_data.shape[:-1]):,}")
    
    # Volume statistics
    report.append("\n" + "=" * 60)
    report.append("VOLUMETRIC ANALYSIS")
    report.append("=" * 60)
    
    volume_stats = calculate_volume_stats(segmentation)
    
    for tumor_type, stats in volume_stats.items():
        report.append(f"\n{tumor_type}:")
        report.append(f"  - Volume: {stats['volume_cm3']:.2f} cmÂ³")
        report.append(f"  - Percentage of brain: {stats['percentage']:.1f}%")
        report.append(f"  - Voxel count: {stats['voxel_count']:,}")
        if stats.get('bbox'):
            report.append(f"  - Bounding box center: {stats['bbox']['center']}")
    
    # Performance metrics
    report.append("\n" + "=" * 60)
    report.append("SEGMENTATION METRICS")
    report.append("=" * 60)
    
    dice_scores = calculate_dice_per_class(segmentation)
    for tumor_class, score in dice_scores.items():
        report.append(f"\n{tumor_class}: Dice Score = {score:.3f}")
    
    # Summary
    report.append("\n" + "=" * 60)
    report.append("CLINICAL SUMMARY")
    report.append("=" * 60)
    
    total_tumor = volume_stats['Total Tumor']
    if total_tumor['volume_cm3'] > 0:
        report.append(f"\nâœ“ Tumor detected")
        report.append(f"âœ“ Total tumor volume: {total_tumor['volume_cm3']:.2f} cmÂ³")
        report.append(f"âœ“ Affects {total_tumor['percentage']:.1f}% of brain volume")
        
        # Severity assessment (simplified)
        if total_tumor['percentage'] < 1:
            severity = "Small"
        elif total_tumor['percentage'] < 5:
            severity = "Moderate"
        else:
            severity = "Large"
        report.append(f"âœ“ Tumor size category: {severity}")
    else:
        report.append("\nâœ“ No tumor detected in this scan")
    
    report.append("\n" + "=" * 60)
    report.append("DISCLAIMER")
    report.append("=" * 60)
    report.append("\nThis is an AI-generated analysis for research purposes only.")
    report.append("Always consult with qualified medical professionals for diagnosis.")
    
    return "\n".join(report)

# Import pandas for data handling
import pandas as pd

# Run the main app
if __name__ == "__main__":
    main()